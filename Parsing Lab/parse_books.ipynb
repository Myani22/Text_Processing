{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8c3340f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Сбор книг: 100%|██████████| 50/50 [02:52<00:00,  3.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Парсинг завершён. Данные сохранены в books.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "import csv\n",
    "from bs4 import BeautifulSoup\n",
    "from random import uniform\n",
    "from tqdm import tqdm\n",
    "from fake_useragent import UserAgent\n",
    "\n",
    "BASE_URL = \"https://books.toscrape.com/catalogue/page-{}.html\"\n",
    "TOTAL_PAGES = 50\n",
    "OUTPUT_CSV = \"books.csv\"\n",
    "\n",
    "# Функция для извлечения рейтинга\n",
    "def get_rating(tag):\n",
    "    if not tag:\n",
    "        return None\n",
    "    classes = tag.get(\"class\", [])\n",
    "    ratings = [\"One\", \"Two\", \"Three\", \"Four\", \"Five\"]\n",
    "    for r in ratings:\n",
    "        if r in classes:\n",
    "            return r\n",
    "    return None\n",
    "\n",
    "# Создаём CSV и записываем заголовки\n",
    "with open(OUTPUT_CSV, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"title\", \"price\", \"rating\", \"availability\", \"book_url\"])\n",
    "\n",
    "# Генератор User-Agent\n",
    "ua = UserAgent()\n",
    "\n",
    "# Основной цикл\n",
    "for page in tqdm(range(1, TOTAL_PAGES + 1), desc=\"Сбор книг\"):\n",
    "    url = BASE_URL.format(page)\n",
    "\n",
    "    # Формируем заголовки со случайным User-Agent\n",
    "    headers = {\n",
    "        \"User-Agent\": ua.random,\n",
    "        \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8\",\n",
    "        \"Accept-Language\": \"en-US,en;q=0.5\",\n",
    "        \"Referer\": \"https://www.google.com/\"\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        # Запрос с таймаутом\n",
    "        resp = requests.get(url, headers=headers, timeout=10)\n",
    "        resp.raise_for_status()                     # выбросит исключение при 4xx/5xx\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"\\nОшибка при загрузке страницы {page}: {e}\")\n",
    "        time.sleep(5)                               # пауза перед следующей попыткой\n",
    "        continue\n",
    "\n",
    "    soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "    books = soup.find_all(\"article\", class_=\"product_pod\")\n",
    "\n",
    "    page_data = []\n",
    "    for book in books:\n",
    "        # Название\n",
    "        title_tag = book.h3.a\n",
    "        title = title_tag.get(\"title\", \"No title\")\n",
    "\n",
    "        # Цена\n",
    "        price_tag = book.find(\"p\", class_=\"price_color\")\n",
    "        price = price_tag.text.strip() if price_tag else \"N/A\"\n",
    "\n",
    "        # Наличие\n",
    "        avail_tag = book.find(\"p\", class_=\"instock availability\")\n",
    "        availability = avail_tag.text.strip() if avail_tag else \"Unknown\"\n",
    "\n",
    "        # Рейтинг\n",
    "        rating_tag = book.find(\"p\", class_=\"star-rating\")\n",
    "        rating = get_rating(rating_tag)\n",
    "\n",
    "        # Ссылка на детальную страницу книги\n",
    "        relative_url = title_tag.get(\"href\", \"\")\n",
    "        full_url = requests.compat.urljoin(BASE_URL, relative_url)\n",
    "\n",
    "        page_data.append([title, price, rating, availability, full_url])\n",
    "\n",
    "    # Сохраняем данные со страницы сразу в CSV\n",
    "    with open(OUTPUT_CSV, \"a\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(page_data)\n",
    "\n",
    "    # Случайная задержка между запросами\n",
    "    sleep_time = uniform(1.5, 3.5)\n",
    "    time.sleep(sleep_time)\n",
    "\n",
    "print(f\"\\nПарсинг завершён. Данные сохранены в {OUTPUT_CSV}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
